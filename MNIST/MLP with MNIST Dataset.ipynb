import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
from tensorflow.contrib.layers.python.layers import batch_norm as batch_norm

mnist = input_data.read_data_sets("MNIST_data/", one_hot=True, validation_size=50000)

print("Training dataset   : ", len(mnist.train.labels),
     "\nTesting dataset    : ", len(mnist.test.labels),
     "\nValidation dataset : ", len(mnist.validation.labels))

learning_rate = 0.001

n_input = 784
n_hidden = 256
n_output = 10

X = tf.placeholder(tf.float32, [None, n_input])
Y = tf.placeholder(tf.float32, [None, n_output])
keep_prob = tf.placeholder(tf.float32)

W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))
L1 = tf.nn.relu(tf.matmul(X, W1))
L1 = tf.nn.dropout(L1, keep_prob)

W2 = tf.Variable(tf.random_normal([n_hidden, n_hidden], stddev=0.01))
L2 = tf.nn.relu(tf.matmul(L1, W2))
L2 = tf.nn.dropout(L2, keep_prob)

W3 = tf.Variable(tf.random_normal([n_hidden, n_hidden], stddev=0.01))
L3 = tf.nn.relu(tf.matmul(L2, W3))
L3 = tf.nn.dropout(L3, keep_prob)

W4 = tf.Variable(tf.random_normal([n_hidden, n_hidden], stddev=0.01))
L4 = tf.nn.relu(tf.matmul(L3, W4))
L4 = tf.nn.dropout(L4, keep_prob)

W5 = tf.Variable(tf.random_normal([n_hidden, n_output], stddev=0.01))
model = tf.matmul(L4, W5)

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))
optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)

init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)

    batch_size = 100
    total_batch = int(mnist.train.num_examples / batch_size)

    for epoch in range(30):
        total_cost = 0

        for i in range(total_batch):
            batch_xs, batch_ys = mnist.train.next_batch(batch_size)

            _, cost_val = sess.run([optimizer, cost],
                                   feed_dict={X: batch_xs,
                                              Y: batch_ys,
                                              keep_prob: 0.7})
            total_cost += cost_val

        if(epoch + 1) % 5 == 0:
            print('Epoch:', '%2d' % (epoch + 1),
                  'Average cost =', '{:.9f}'.format(total_cost / total_batch))

    is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))
    
    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))
    print('Accuracy:', accuracy.eval({X: mnist.test.images[:200],
                                       Y: mnist.test.labels[:200],
                                       keep_prob: 1}))